'use client'

import React, { useState, useEffect, useRef, useCallback } from 'react'
import { MessageSquare, Upload } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { AudioPlayer } from './audio-player'
import { useAuth } from '@/hooks/useAuth'
import { toast } from 'sonner'

interface HeaderProps {
  isRecording: boolean
  onAISummary?: () => void
  isLoadingSummary?: boolean
  sessionId?: string
  onAudioTimeUpdate?: (currentTime: number) => void
  onAudioSeekTo?: (time: number) => void
  onRefreshSessions?: () => void
  onRefreshAudio?: () => Promise<void>
  apiClient?: unknown
}

export function Header({ 
  isRecording, 
  onAISummary,
  isLoadingSummary = false,
  sessionId,
  onAudioTimeUpdate,
  onAudioSeekTo,
  onRefreshSessions,
  onRefreshAudio,
  apiClient
}: HeaderProps) {
  const [audioUrl, setAudioUrl] = useState<string>()
  const [hasAudio, setHasAudio] = useState(false)
  const [isUploading, setIsUploading] = useState(false)
  const fileInputRef = useRef<HTMLInputElement>(null)
  
  // ä½¿ç”¨useAuthè·å–è®¤è¯çŠ¶æ€
  const { session } = useAuth()
  
  // ä½¿ç”¨useRefæ¥è·Ÿè¸ªå‰ä¸€ä¸ªå½•éŸ³çŠ¶æ€
  const wasRecordingRef = useRef(isRecording)

  // æ£€æŸ¥ä¼šè¯æ˜¯å¦æœ‰éŸ³é¢‘æ–‡ä»¶
  const checkSessionAudio = useCallback(async (sessionId: string) => {
    try {
      // å¦‚æœsessionIdä¸ºç©ºï¼Œç›´æ¥è¿”å›
      if (!sessionId) {
        console.log('âš ï¸ sessionIdä¸ºç©ºï¼Œè·³è¿‡éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥')
        return
      }
      
      console.log('ğŸ” æ£€æŸ¥ä¼šè¯éŸ³é¢‘æ–‡ä»¶:', sessionId)

      // ä½¿ç”¨useAuthä¸­çš„sessionè·å–token
      const token = session?.access_token

      const response = await fetch(`/api/v1/sessions/${sessionId}/audio_files`, {
        headers: {
          ...(token && { 'Authorization': `Bearer ${token}` })
        }
      })
      
      console.log('ğŸŒ Audio files APIå“åº”:', {
        status: response.status,
        statusText: response.statusText,
        sessionId: sessionId,
        hasToken: !!token
      })
      
      if (response.ok) {
        const data = await response.json()
        console.log('ğŸ“Š Audio filesæ•°æ®:', data)
        
        if (data && data.length > 0) {
          const audioFile = data[0] // å–ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶
          console.log('ğŸ“ æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:', audioFile)
          
          // å°†åŸå§‹URLè½¬æ¢ä¸ºé€šè¿‡ä»£ç†è®¿é—®çš„URL
          const originalUrl = audioFile.public_url
          let proxyUrl = originalUrl
          
          // å¦‚æœæ˜¯HTTPåœ°å€ï¼Œè½¬æ¢ä¸ºä»£ç†è·¯å¾„
          if (originalUrl && originalUrl.startsWith('http://localhost:54321/')) {
            proxyUrl = originalUrl.replace('http://localhost:54321/', '/')
          } else if (originalUrl && originalUrl.includes('localhost:54321')) {
            // å¤„ç†å…¶ä»–å¯èƒ½çš„æ ¼å¼
            proxyUrl = originalUrl.replace(/https?:\/\/[^/]*localhost:54321\//, '/')
          }
          
          setAudioUrl(proxyUrl)
          setHasAudio(true)
          console.log('âœ… éŸ³é¢‘URLå·²è®¾ç½®:', proxyUrl, '(åŸå§‹URL:', originalUrl, ')')
        } else {
          console.log('ğŸ“­ è¯¥ä¼šè¯æš‚æ— éŸ³é¢‘æ–‡ä»¶')
          setHasAudio(false)
          setAudioUrl(undefined)
        }
      } else {
        console.error('âŒ è·å–éŸ³é¢‘æ–‡ä»¶APIå¤±è´¥:', response.status, response.statusText)
        setHasAudio(false)
        setAudioUrl(undefined)
      }
    } catch (error) {
      console.error('âŒ è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥:', error)
      setHasAudio(false)
      setAudioUrl(undefined)
    }
  }, [session?.access_token])

  // Handle audio file import
  const handleAudioImport = () => {
    if (isRecording) {
      toast.warning('å½•éŸ³è¿›è¡Œä¸­ï¼Œæ— æ³•å¯¼å…¥éŸ³é¢‘æ–‡ä»¶')
      return
    }
    
    if (fileInputRef.current) {
      fileInputRef.current.click()
    }
  }

  // Handle file selection
  const handleFileSelect = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files
    if (!files || files.length === 0) return

    const selectedFiles = Array.from(files)
    console.log('ğŸ“ é€‰æ‹©çš„æ–‡ä»¶:', selectedFiles.map(f => ({ name: f.name, size: f.size, type: f.type })))

    // Check file formats
    const validFiles = selectedFiles.filter(file => {
      const fileName = file.name.toLowerCase()
      const isWav = fileName.endsWith('.wav') || file.type === 'audio/wav' || file.type === 'audio/x-wav'
      const isMp3 = fileName.endsWith('.mp3') || file.type === 'audio/mpeg' || file.type === 'audio/mp3'
      const isValidFormat = isWav || isMp3
      
      if (!isValidFormat) {
        console.log('âŒ æ–‡ä»¶æ ¼å¼æ£€æŸ¥å¤±è´¥:', { name: file.name, type: file.type, fileName })
        toast.error(`æ–‡ä»¶ ${file.name} æ ¼å¼ä¸æ”¯æŒï¼Œä»…æ”¯æŒ WAV å’Œ MP3 æ ¼å¼`)
      } else {
        console.log('âœ… æ–‡ä»¶æ ¼å¼æ£€æŸ¥é€šè¿‡:', { name: file.name, type: file.type })
      }
      return isValidFormat
    })

    if (validFiles.length === 0) {
      toast.error('æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶')
      return
    }

    if (validFiles.length > 1) {
      toast.error('æš‚æ—¶åªæ”¯æŒå•ä¸ªæ–‡ä»¶å¯¼å…¥')
      return
    }

    const file = validFiles[0]
    await processBatchTranscription(file)
    
    // Clear input value for next selection
    event.target.value = ''
  }

  // Process batch transcription
  const processBatchTranscription = async (file: File) => {
    if (!apiClient) {
      toast.error('APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–')
      return
    }

    setIsUploading(true)
    
    try {
      // Check file format and show appropriate message
      const isMP3 = file.type === 'audio/mpeg' || file.type === 'audio/mp3'
      const isWAV = file.type === 'audio/wav'
      
      let formatInfo = ''
      if (isMP3) {
        formatInfo = ' (å°†è½¬æ¢ä¸ºWAVå¤„ç†ï¼Œå­˜å‚¨ä¸ºMP3)'
      } else if (isWAV) {
        formatInfo = ' (å°†è½¬æ¢ä¸ºWAVå¤„ç†ï¼Œå­˜å‚¨ä¸ºMP3)'
      }
      
      toast.info(`å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: ${file.name}${formatInfo}`)
      
      // Call backend batch transcription API using APIClient pattern
      const token = session?.access_token
      if (!token) {
        toast.error('ç”¨æˆ·æœªè®¤è¯')
        return
      }
      
      // Prepare form data for API call
      const formData = new FormData()
      formData.append('audio_file', file)
      
      // Debug: log file details before sending
      console.log('ğŸ” å‘é€çš„æ–‡ä»¶è¯¦æƒ…:', {
        name: file.name,
        size: file.size,
        type: file.type,
        lastModified: file.lastModified
      })
      
      // Direct call to backend API with proper authentication
      // Note: Don't set Content-Type header for FormData, browser will set it automatically
      const response = await fetch('/api/v1/transcriptions/batch', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`,
        },
        body: formData
      })
      
      if (!response.ok) {
        const errorData = await response.json()
        throw new Error(errorData.error || 'æ‰¹é‡è½¬å½•å¤±è´¥')
      }
      
      const result = await response.json()
      console.log('âœ… æ‰¹é‡è½¬å½•å®Œæˆ:', result)
      
              // Display detailed success message with statistics
        if (result.status === 'completed' && result.statistics) {
          const stats = result.statistics
          toast.success(
            `ğŸ‰ éŸ³é¢‘æ–‡ä»¶è½¬å½•å®Œæˆï¼\n` +
            `ğŸ“ æ–‡ä»¶: ${file.name}\n` +
            `ğŸ—£ï¸ è¯´è¯äººæ•°: ${stats.speaker_count}\n` +
            `ğŸ“Š è½¬å½•ç‰‡æ®µ: ${stats.total_segments}ä¸ª\n` +
            `â±ï¸ æ€»æ—¶é•¿: ${Math.round(stats.total_duration_seconds)}ç§’\n` +
            `ğŸ“ è½¬å½•å­—æ•°: ${stats.transcription_length}å­—\n` +
            `ğŸ’¾ å­˜å‚¨æ ¼å¼: MP3`,
            { duration: 8000 }
          )
      } else if (result.status === 'placeholder') {
        toast.success('éŸ³é¢‘æ–‡ä»¶å·²æ¥æ”¶ï¼Œæ‰¹é‡è½¬å½•åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­')
      } else {
        toast.success('éŸ³é¢‘æ–‡ä»¶è½¬å½•å®Œæˆ')
      }
      
      // Refresh file list and session data
      if (onRefreshSessions) {
        onRefreshSessions()
      }
      
    } catch (error) {
      console.error('âŒ æ‰¹é‡è½¬å½•å¤±è´¥:', error)
      toast.error(`å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`)
    } finally {
      setIsUploading(false)
    }
  }

  // å½“sessionIdå˜åŒ–æ—¶æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
  useEffect(() => {
    if (sessionId) {
      checkSessionAudio(sessionId)
    } else {
      // å½“sessionIdä¸ºç©ºæ—¶ï¼Œæ¸…ç†éŸ³é¢‘çŠ¶æ€
      setHasAudio(false)
      setAudioUrl(undefined)
      console.log('ğŸ§¹ æ¸…ç†éŸ³é¢‘çŠ¶æ€ï¼šsessionIdä¸ºç©º')
    }
  }, [sessionId, checkSessionAudio])

  // å½“å½•éŸ³ç»“æŸæ—¶é‡æ–°æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
  useEffect(() => {
    if (wasRecordingRef.current && !isRecording && sessionId) {
      // å½•éŸ³åˆšç»“æŸï¼Œç­‰å¾…ä¸€ä¸‹åé‡æ–°æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
      console.log('ğŸ”„ å½•éŸ³ç»“æŸï¼Œå°†åœ¨5ç§’åé‡æ–°æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶:', sessionId)
      setTimeout(() => {
        console.log('ğŸ” å¼€å§‹é‡æ–°æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶:', sessionId)
        checkSessionAudio(sessionId)
      }, 5000) // ç­‰å¾…5ç§’ç¡®ä¿finalize sessionå®Œæˆ
    }
    
    wasRecordingRef.current = isRecording
  }, [isRecording, sessionId, checkSessionAudio])

  // æš´éœ²åˆ·æ–°éŸ³é¢‘æ–‡ä»¶çš„æ–¹æ³•
  const refreshAudioFiles = useCallback(async () => {
    if (sessionId) {
      console.log('ğŸ”„ æ‰‹åŠ¨åˆ·æ–°éŸ³é¢‘æ–‡ä»¶:', sessionId)
      await checkSessionAudio(sessionId)
    }
  }, [sessionId, checkSessionAudio])
  
  // å½“çˆ¶ç»„ä»¶è¯·æ±‚åˆ·æ–°éŸ³é¢‘æ—¶
  useEffect(() => {
    if (onRefreshAudio) {
      onRefreshAudio.current = refreshAudioFiles
    }
  }, [refreshAudioFiles, onRefreshAudio])

  return (
    <div className="h-16 bg-white border-b border-gray-200 px-6 flex items-center flex-shrink-0">
      {/* Audio Player - Full Width */}
      <div className="flex-1 flex items-center space-x-4">
        {hasAudio && !isRecording ? (
          <AudioPlayer 
            audioUrl={audioUrl}
            isVisible={hasAudio && !isRecording}
            className="flex-1"
            onTimeUpdate={onAudioTimeUpdate}
            onSeekTo={onAudioSeekTo}
          />
        ) : (
          <div className="flex-1 flex items-center justify-center">
            {!hasAudio && !isRecording && sessionId && (
              <span className="text-sm text-gray-400">æš‚æ— éŸ³é¢‘æ–‡ä»¶</span>
            )}
            {isRecording && (
              <span className="text-sm text-red-600">å½•éŸ³ä¸­...</span>
            )}
          </div>
        )}

        {/* Action Buttons */}
        <div className="flex items-center space-x-2 flex-shrink-0">
          {/* AI Summary Button */}
          <Button 
            variant="outline" 
            className="text-blue-600 border-blue-200 hover:bg-blue-50 text-sm px-3 h-8"
            onClick={() => onAISummary?.()}
            disabled={isLoadingSummary || isRecording}
          >
            <MessageSquare className="h-4 w-4 mr-2" />
            {isLoadingSummary ? 'ç”Ÿæˆä¸­...' : 'AI æ€»ç»“'}
          </Button>

          {/* Audio Import Button */}
          <Button 
            variant="outline" 
            className="text-green-600 border-green-200 hover:bg-green-50 text-sm px-3 h-8"
            onClick={handleAudioImport}
            disabled={isUploading || isRecording}
          >
            <Upload className="h-4 w-4 mr-2" />
            {isUploading ? 'å¤„ç†ä¸­...' : 'å¯¼å…¥éŸ³é¢‘'}
          </Button>
        </div>
      </div>

      {/* Hidden file input */}
      <input
        ref={fileInputRef}
        type="file"
        accept=".wav,.mp3,audio/wav,audio/mpeg,audio/mp3"
        multiple
        onChange={handleFileSelect}
        style={{ display: 'none' }}
      />
    </div>
  )
} 